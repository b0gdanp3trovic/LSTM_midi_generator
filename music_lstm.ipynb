{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pretty_midi\n",
    "from keras.layers import Bidirectional, LSTM, Input, Activation,Dropout, Dense, Flatten, CuDNNLSTM, AveragePooling3D\n",
    "from keras.models import Sequential\n",
    "import glob\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import BatchNormalization as BatchNorm\n",
    "from music21 import converter, instrument, note, chord\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up CUDA and import tensorflow\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "os.add_dll_directory(\"C:/tools/cuda\")\n",
    "os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.5/bin\")\n",
    "\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras import activations\n",
    "tensorflow.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------MONOPHONIC------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# read notes\n",
    "\n",
    "notesl = []\n",
    "for file in glob.glob(\"midifiles/*.mid\"):\n",
    "    midi = converter.parse(file)\n",
    "    notes_arr = None\n",
    "    try:\n",
    "        s2 = instrument.partitionByInstrument(midi)\n",
    "        notes_arr = s2.parts[0].recurse() \n",
    "    except:\n",
    "        notes_arr = midi.flat.notes\n",
    "    for element in notes_arr:\n",
    "        if isinstance(element, note.Note):\n",
    "            notesl.append(element.pitch.implicitOctave)\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            for n in element.normalOrder:\n",
    "                notesl.append(n)\n",
    "\n",
    "\n",
    "notes_from_midi = []\n",
    "for n in notesl:\n",
    "    to_add = np.zeros(128)\n",
    "    to_add[n] = 1\n",
    "    notes_from_midi.append(to_add)\n",
    "\n",
    "notes_from_midi = np.asarray(notes_from_midi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse notes_arr and build one-hot encoded series of vectors containing\n",
    "# notes in every timestamp (0.5 second iterations)\n",
    "\n",
    "def parse_timestamps():\n",
    "    for idx, timestamp in enumerate(timestamps):\n",
    "        which_notes = np.zeros(128)\n",
    "        for note_from_midi in notes_from_midi:\n",
    "            if(note_from_midi.start <= timestamp and note_from_midi.end >= timestamp):\n",
    "                notes_arr[note_from_midi.pitch][idx] = 1\n",
    "\n",
    "    notes_arr = notes_arr.transpose()\n",
    "    print(notes_arr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_zero(a):\n",
    "    for num in a:\n",
    "        if(num != 0):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_arrays(a, b):\n",
    "    for i in range(len(a)):\n",
    "        if(a[i] != b[i]):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_notes(a, b):\n",
    "    new = np.zeros(128)\n",
    "    for idx, note in enumerate(b):\n",
    "        if(b[idx] == 1):\n",
    "            if(a[idx] == 0):\n",
    "                new[idx]=1\n",
    "        else:\n",
    "            new[idx]=0\n",
    "    return new\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_bincrossentropy(true, pred, weight_zero = 0.15, weight_one = 0.85):\n",
    "  \n",
    "    # calculate the binary cross entropy\n",
    "    bin_crossentropy = keras.backend.binary_crossentropy(true, pred)\n",
    "    \n",
    "    # apply the weights\n",
    "    weights = true * weight_one + (1. - true) * weight_zero\n",
    "    weighted_bin_crossentropy = weights * bin_crossentropy \n",
    "\n",
    "    return keras.backend.mean(weighted_bin_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_from_midi = np.asarray(notes_from_midi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "seq_len = 35\n",
    "net_in = []\n",
    "net_out = []\n",
    "i = 0\n",
    "\n",
    "\n",
    "while i < notes_from_midi.shape[0] - seq_len:\n",
    "    seq_in = notes_from_midi[i:i + seq_len]\n",
    "    seq_out = notes_from_midi[i+seq_len-1]\n",
    "    net_in.append(seq_in)\n",
    "    net_out.append(seq_out)\n",
    "    \n",
    "    i+=1\n",
    "net_in = np.asarray(net_in)\n",
    "net_out = np.asarray(net_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "    512,\n",
    "    input_shape=(100, net_in.shape[2]),\n",
    "    return_sequences=True\n",
    "))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(512))\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('softmax'))\n",
    "#optimizer = tensorflow.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 100, 512)          1312768   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100, 512)          0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 512)               2099200   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,576,192\n",
      "Trainable params: 3,576,192\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath,\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(net_in, net_out, epochs=200, batch_size=64, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random(n_notes):\n",
    "    for i in range(100):\n",
    "        note1 = np.random.randint(128)\n",
    "        new = np.zeros(128)\n",
    "        new[note1] = 1\n",
    "        rand_init.append(new)\n",
    "    return rand_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "# we generate a random note 100 times to initialize prediction\n",
    "\n",
    "start = np.random.randint(0, len(net_in)-1)\n",
    "start_j = np.random.randint(0, len(net_in[start])-1)\n",
    "rand_init = []\n",
    "for i in range(100):\n",
    "    note1 = np.random.randint(128)\n",
    "    new = np.zeros(128)\n",
    "    new[note1] = 1\n",
    "    rand_init.append(new)\n",
    "pattern = rand_init\n",
    "pred_out = []\n",
    "for note_index in range(1000):\n",
    "    pred_input = np.reshape(pattern, (1, len(pattern), 128))\n",
    "    prediction = model.predict(pred_input, verbose=0)\n",
    "    res = np.asarray([num > np.mean(prediction[0]) * 4 for num in prediction[0]]).astype(int)\n",
    "    #res = reject_outliers(prediction, 3)\n",
    "    pred_out.append(res)\n",
    "    pattern = np.vstack((get_random(100), res))\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse repeating notes in neighbouring timestamps as one note with a longer duration\n",
    "def cleanup_midi(obj_piano):\n",
    "    obj = pretty_midi.PrettyMIDI()\n",
    "    piano_program = pretty_midi.instrument_name_to_program('Cello')\n",
    "    obj_piano_new = pretty_midi.Instrument(program=piano_program)\n",
    "    marked_for_removal = []\n",
    "    for note_i in obj_piano.notes:\n",
    "        for idx, note_j in enumerate(obj_piano.notes):\n",
    "            if(note_i.pitch == note_j.pitch and note_j.start == note_i.start + 0.5):\n",
    "                print(idx)\n",
    "                marked_for_removal.append(idx)\n",
    "                note_i.end += 0.5\n",
    "    for idx,note in enumerate(obj_piano.notes):\n",
    "        if idx not in marked_for_removal:\n",
    "            obj_piano_new.notes.append(obj_piano.notes[idx])\n",
    "    return obj_piano_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid too high notes\n",
    "def normalize_pitches(obj_piano):\n",
    "    for note in obj_piano.notes:\n",
    "        if note.pitch > 75:\n",
    "            note.pitch -=16\n",
    "    return obj_piano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to midi and add a note each 0.5 seconds\n",
    "time = 0\n",
    "obj = pretty_midi.PrettyMIDI()\n",
    "piano_program = pretty_midi.instrument_name_to_program('Cello')\n",
    "obj_piano = pretty_midi.Instrument(program=piano_program)\n",
    "for pred in pred_out:\n",
    "    pitches = [idx for idx,num in enumerate(pred) if num == 1]\n",
    "    print(pitches)\n",
    "    if(len(pitches) > 0):\n",
    "        note = pretty_midi.Note(velocity=100, pitch=pitches[0], start = time, end = time)\n",
    "        for pitch in pitches:\n",
    "            note = pretty_midi.Note(velocity=100, pitch=pitch, start = time, end = time+0.5)\n",
    "            obj_piano.notes.append(note)\n",
    "        time += 0.5\n",
    "obj.instruments.append(obj_piano)\n",
    "obj.write('generated.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------POLYPHONIC-------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = []\n",
    "for file in glob.glob(\"midifiles/*.mid\"):\n",
    "    midi = converter.parse(file)\n",
    "    print(\"Parsing %s\" % file)\n",
    "    notes_to_parse = midi.flat.notes\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "            \n",
    "total_pitches = len(set(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.np_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-11f53d7f4c07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.np_utils'"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import keras.np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 70\n",
    "\n",
    "net_in = []\n",
    "net_out = []\n",
    "\n",
    "pitches_in_data = sorted(set(item for item in notes))\n",
    "\n",
    "note_mapping = dict((note, number) for number, note in enumerate(pitches_in_data))\n",
    "for i in range(0, len(notes) - seq_len, 1):\n",
    "    seq_in = notes[i:i + seq_len]\n",
    "    seq_out = notes[i + seq_len]\n",
    "    net_in.append([note_mapping[char] for char in seq_in])\n",
    "    net_out.append(note_mapping[seq_out])\n",
    "\n",
    "n_patterns = len(net_in)\n",
    "net_in = numpy.reshape(net_in, (n_patterns, seq_len, 1))\n",
    "net_in = net_in / float(total_pitches)\n",
    "\n",
    "net_out = np_utils.to_categorical(net_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(\n",
    "    512,\n",
    "    input_shape=(net_in.shape[1], net_in.shape[2]),\n",
    "    return_sequences=True\n",
    "))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(CuDNNLSTM(512, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(CuDNNLSTM(1024))\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(n_vocab))\n",
    "model.add(Activation('softmax'))\n",
    "#optimizer = tensorflow.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cu_dnnlstm_6 (CuDNNLSTM)    (None, 70, 512)           1054720   \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 70, 512)           0         \n",
      "                                                                 \n",
      " cu_dnnlstm_7 (CuDNNLSTM)    (None, 70, 512)           2101248   \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 70, 512)           0         \n",
      "                                                                 \n",
      " cu_dnnlstm_8 (CuDNNLSTM)    (None, 1024)              6299648   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 358)               92006     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 358)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,810,022\n",
      "Trainable params: 9,810,022\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filepath = \"{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath,\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(net_in, net_out, epochs=200, batch_size=32, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = numpy.random.randint(0, len(net_in)-1)\n",
    "\n",
    "note_mapping = dict((number, note) for number, note in enumerate(pitches_in_data))\n",
    "\n",
    "pattern = net_in[start]\n",
    "pred_out = []\n",
    "\n",
    "for note_index in range(500):\n",
    "    pred_in = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction_input = pred_in / float(n_vocab)\n",
    "\n",
    "    prediction = model.predict(pred_in, verbose=0)\n",
    "\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_note[index]\n",
    "    pred_out.append(result)\n",
    "\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to midi and add a note each 0.5 seconds\n",
    "time = 0\n",
    "obj = pretty_midi.PrettyMIDI()\n",
    "piano_program = pretty_midi.instrument_name_to_program('Cello')\n",
    "obj_piano = pretty_midi.Instrument(program=piano_program)\n",
    "for pred in pred_out:\n",
    "    pitches = [idx for idx,num in enumerate(pred) if num == 1]\n",
    "    print(pitches)\n",
    "    if(len(pitches) > 0):\n",
    "        note = pretty_midi.Note(velocity=100, pitch=pitches[0], start = time, end = time)\n",
    "        for pitch in pitches:\n",
    "            note = pretty_midi.Note(velocity=100, pitch=pitch, start = time, end = time+0.5)\n",
    "            obj_piano.notes.append(note)\n",
    "        time += 0.5\n",
    "obj.instruments.append(obj_piano)\n",
    "obj.write('generated.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------ANOTHER MONOPHONIC WAY--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    for note_index in range(500):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        index = np.argmax(prediction)\n",
    "        print(index)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "        \n",
    "        pattern = np.append(pattern, index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow.experimental.config.list_physical_devices('GPU')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x = 79\n",
    "max_T_x = 1000\n",
    "sequence_length = 20\n",
    "T_y_generated = 200\n",
    "\n",
    "DIR = './'\n",
    "import urllib.request\n",
    "midiFile_l = ['cs1-2all.mid', 'cs5-1pre.mid', 'cs4-1pre.mid', 'cs3-5bou.mid', 'cs1-4sar.mid', 'cs2-5men.mid', 'cs3-3cou.mid', 'cs2-3cou.mid', 'cs1-6gig.mid', 'cs6-4sar.mid', 'cs4-5bou.mid', 'cs4-3cou.mid', 'cs5-3cou.mid', 'cs6-5gav.mid', 'cs6-6gig.mid', 'cs6-2all.mid', 'cs2-1pre.mid', 'cs3-1pre.mid', 'cs3-6gig.mid', 'cs2-6gig.mid', 'cs2-4sar.mid', 'cs3-4sar.mid', 'cs1-5men.mid', 'cs1-3cou.mid', 'cs6-1pre.mid', 'cs2-2all.mid', 'cs3-2all.mid', 'cs1-1pre.mid', 'cs5-2all.mid', 'cs4-2all.mid', 'cs5-5gav.mid', 'cs4-6gig.mid', 'cs5-6gig.mid', 'cs5-4sar.mid', 'cs4-4sar.mid', 'cs6-3cou.mid']\n",
    "for midiFile in midiFile_l:\n",
    "    urllib.request.urlretrieve (\"http://www.jsbach.net/midi/\" + midiFile, DIR + midiFile)\n",
    "nbExample = len(midiFile_l)\n",
    "\n",
    "midiFile_l = glob.glob(DIR + 'cs*.mid')\n",
    "print(midiFile_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We truncate the duration of each example to the first T_x data\n",
    "\n",
    "X_list = []\n",
    "\n",
    "for file in midiFile_l:\n",
    "    midi_data = pretty_midi.PrettyMIDI(midiFile)\n",
    "    note_l = [note.pitch for note in midi_data.instruments[0].notes]\n",
    "    T_x = len(note_l)\n",
    "    if T_x > max_T_x:\n",
    "        T_x = max_T_x\n",
    "    X_ohe = np.zeros((T_x, n_x))\n",
    "    for t in range(T_x): \n",
    "        X_ohe[t, note_l[t]-1] = 1\n",
    "    # add to the list  \n",
    "    X_list.append(X_ohe)\n",
    "    \n",
    "print(len(X_list))\n",
    "print(X_list[0].shape)\n",
    "print(X_list[1].shape)\n",
    "print(X_list[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    notes = []\n",
    "\n",
    "    for file in glob.glob(\"midifiles/*.mid\"):\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        notes_to_parse = midi.flat.notes\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch.implicitOctave))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = get_notes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_l = [note for note in notes]\n",
    "# convert to one-hot-encoding\n",
    "T_x = len(note_l)\n",
    "print(T_x)\n",
    "X_ohe = np.zeros((T_x, n_x))\n",
    "\n",
    "for t in range(T_x):\n",
    "    if(len(str(note_l[t])) == 1):\n",
    "        X_ohe[t, int(note_l[t])-1] = 1\n",
    "    else:\n",
    "        pitches = note_l[t].split('.')\n",
    "        for pitch in pitches:\n",
    "            X_ohe[t, int(pitch)-1] = 1\n",
    "    # add to the list  \n",
    "X_list.append(X_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We truncate the duration of each example to the first T_x data\n",
    "\n",
    "X_list = []\n",
    "\n",
    "for midiFile in midiFile_l:\n",
    "    # read the MIDI file\n",
    "    midi = converter.parse(midiFile)\n",
    "\n",
    "    print(\"Parsing %s\" % midiFile)\n",
    "\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    note_l = midi.flat.notes\n",
    "\n",
    "    # convert to one-hot-encoding\n",
    "    T_x = len(note_l)\n",
    "    if T_x > max_T_x:\n",
    "      T_x = max_T_x\n",
    "    X_ohe = np.zeros((T_x, n_x))\n",
    "    for t in range(T_x):\n",
    "        if isinstance(note_l[t], note.Note):\n",
    "            X_ohe[t, int(note_l[t].pitch.implicitOctave)-1] = 1\n",
    "        elif isinstance(note_l[t], chord.Chord):\n",
    "            for el in note_l[t].normalOrder:\n",
    "                X_ohe[t, el-1]=1\n",
    "    # add to the list  \n",
    "    print(X_ohe.shape)\n",
    "    X_list.append(X_ohe)\n",
    "    \n",
    "print(len(X_list))\n",
    "print(X_list[0].shape)\n",
    "print(X_list[1].shape)\n",
    "print(X_list[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = []\n",
    "y_train_list = []\n",
    "\n",
    "X_train_list = [X_list[i][t:t+sequence_length] for i in range(len(X_list)) for t in range(len(X_list[i])-sequence_length)]\n",
    "y_train_list = [X_list[i][t+ sequence_length] for i in range(len(X_list)) for t in range(len(X_list[i])-sequence_length)]\n",
    "\n",
    "X_train = np.asarray(X_train_list)\n",
    "y_train = np.asarray(y_train_list)\n",
    "\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network():\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(CuDNNLSTM(\n",
    "        512,\n",
    "        input_shape=(20, 79),\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(CuDNNLSTM(256, return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(CuDNNLSTM(256))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(79))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = np.random.randint(0, len(X_train_list)-1)\n",
    "pattern = X_train_list[start]\n",
    "print(start)\n",
    "print(pattern.shape)\n",
    "print(np.expand_dims(pattern, 0).shape)\n",
    "\n",
    "model = tpu_model.sync_to_cpu()\n",
    "note_l = []\n",
    "prediction_l = []\n",
    "\n",
    "for note_index in range(T_y_generated):\n",
    "    pred = model.predict(np.expand_dims(pattern[note_index:,:], 0))\n",
    "    prediction_l.append(pred)\n",
    "    note = np.argmax(pred, axis=1)\n",
    "    note_l.append(note)\n",
    "    note_ohe = np.zeros(79)\n",
    "    note_ohe[note] = 1\n",
    "    pattern = np.vstack((pattern, note_ohe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_out = prediction_l\n",
    "# write to midi and add a note each 0.5 seconds\n",
    "time = 0\n",
    "obj = pretty_midi.PrettyMIDI()\n",
    "piano_program = pretty_midi.instrument_name_to_program('Cello')\n",
    "obj_piano = pretty_midi.Instrument(program=piano_program)\n",
    "for pred in pred_out:\n",
    "    pitches = [idx for idx,num in enumerate(pred) if num == 1]\n",
    "    print(pitches)\n",
    "    if(len(pitches) > 0):\n",
    "        note = pretty_midi.Note(velocity=100, pitch=pitches[0], start = time, end = time)\n",
    "        for pitch in pitches:\n",
    "            note = pretty_midi.Note(velocity=100, pitch=pitch, start = time, end = time+0.5)\n",
    "            obj_piano.notes.append(note)\n",
    "        time += 0.5\n",
    "obj.instruments.append(obj_piano)\n",
    "obj.write('generated.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(16, 8), dpi=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(folder_name):\n",
    "    losses = []\n",
    "    for file in glob.glob(f\"{folder_name}/*.hdf5\"):\n",
    "    name = file.split('-')[1]\n",
    "    losses.append(float(name))\n",
    "    losses = sorted(losses, reverse=True)\n",
    "    plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot([x for x in range(len(losses))], losses)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
